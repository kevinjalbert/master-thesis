\chapter{Summary and Conclusions}
\label{chap:conclusions}


\section{Summary}
\label{sec:conclusions_summary}


\section{Contributions}
\label{sec:conclusions_contributions}


\section{Limitations}
\label{sec:conclusions_limitations}


\section{Future Work}
\label{sec:conclusions_future_work}


\section{Conclusions}
\label{sec:conclusions_conclusions}
Our technique for predicting mutation score using source code and test suite metrics outperforms random with an achieved accuracy of 58.27\% and 54.82\% with the JGAP data, for classes and methods respectively. These results have not been optimized and we believe that with further enhancements and a more tailored feature set we may be able to increase the prediction accuracy.

Despite the promising initial results there is an obvious threat to external validity since we have applied our predictive technique to a single open source project -- JGAP. Additionally, we performed training and prediction from the same project. As stated by Kitchenham and Mendes \textit{``It is invalid to select one or two datasets to `prove' the validity of a new technique because we cannot be sure that, of the many published datasets, those chosen are the only ones that favour the new technique''}~\cite{KM09}. Thus, we plan to evaluate more open source projects using our prediction technique to better assess the prediction accuracy. With more data we plan to investigate whether cross-project models are valid for mutation score prediction. We would also like to consider projects with more varied mutation scores to explore the variation in prediction accuracy between strong and weak test suites. A final area of future work is to expand the set of mutation operators used to include object oriented and concurrency operators.
